{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CACHE_DIR = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url: str, fname: str, chunk_size=1024):\n",
    "    \"\"\"发送HTTP GET请求以流式方式获取文件\"\"\"\n",
    "    resp = requests.get(url, stream=True)\n",
    "    \n",
    "    # 获取文件的总大小（以字节为单位），默认为0如果没有提供'content-length'头信息\n",
    "    total = int(resp.headers.get(\"content-length\", 0))\n",
    "    \n",
    "    # 以写二进制模式打开一个文件以保存下载的内容\n",
    "    with open(fname, \"wb\") as file, tqdm(\n",
    "        desc=fname,           # 进度条前面的描述信息（通常是文件名）\n",
    "        total=total,          # 总的字节数，用于设置进度条的总长度\n",
    "        unit=\"iB\",            # 进度条的单位，'iB'代表二进制字节\n",
    "        unit_scale=True,      # 启用单位缩放，如KB、MB等\n",
    "        unit_divisor=1024,    # 设置单位换算的除数，这里为1024\n",
    "    ) as bar:\n",
    "        # 逐块读取响应内容并写入文件\n",
    "        for data in resp.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)  # 写入数据块到文件\n",
    "            bar.update(size)         # 更新进度条\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    \"\"\"在DATA_CACHE_DIR中创建目录，如果目录不存在则创建\"\"\"\n",
    "    os.makedirs(DATA_CACHE_DIR, exist_ok=True)\n",
    "\n",
    "    # 定义TinyStories数据集的下载URL和保存的文件名\n",
    "    data_url = \"https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStories_all_data.tar.gz\"\n",
    "    data_filename = os.path.join(DATA_CACHE_DIR, \"TinyStories_all_data.tar.gz\")\n",
    "    \n",
    "    # 检查数据集是否已经下载，如果没有下载则进行下载\n",
    "    if not os.path.exists(data_filename):\n",
    "        print(f\"Downloading {data_url} to {data_filename}...\")\n",
    "        download_file(data_url, data_filename)  # 使用之前定义的download_file函数进行下载\n",
    "    else:\n",
    "        print(f\"{data_filename} already exists, skipping download...\")\n",
    "\n",
    "    # 定义解压缩后的数据目录\n",
    "    data_dir = os.path.join(DATA_CACHE_DIR, \"TinyStories_all_data\")\n",
    "    \n",
    "    # 检查数据目录是否存在，如果不存在则解压缩数据集\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir, exist_ok=True)  # 创建数据目录\n",
    "        print(f\"Unpacking {data_filename}...\")\n",
    "        os.system(f\"tar -xzf {data_filename} -C {data_dir}\")  # 使用系统命令解压缩.tar.gz文件\n",
    "    else:\n",
    "        print(f\"{data_dir} already exists, skipping unpacking...\")\n",
    "\n",
    "    # 查找解压后的所有JSON文件，排序后获取文件名列表\n",
    "    shard_filenames = sorted(glob.glob(os.path.join(data_dir, \"*.json\")))\n",
    "    \n",
    "    # 打开第一个JSON文件并读取内容\n",
    "    with open(shard_filenames[0], \"r\") as f:\n",
    "        data = json.load(f)  # 将JSON文件内容加载到变量data中\n",
    "    \n",
    "    print(\"Download done.\")  # 下载完成信息\n",
    "    print(f\"Number of shards: {len(shard_filenames)}\")  # 打印解压后数据分片的数量\n",
    "    print(f\"Example story:\\n{data[0]}\")  # 打印第一个分片中的一个示例故事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/TinyStories_all_data.tar.gz already exists, skipping download...\n",
      "data/TinyStories_all_data already exists, skipping unpacking...\n",
      "Download done.\n",
      "Number of shards: 50\n",
      "Example story:\n",
      "{'story': '\\n\\nLily and Ben are friends. They like to play in the park. One day, they see a big tree with a swing. Lily wants to try the swing. She runs to the tree and climbs on the swing.\\n\"Push me, Ben!\" she says. Ben pushes her gently. Lily feels happy. She swings higher and higher. She laughs and shouts.\\nBen watches Lily. He thinks she is cute. He wants to swing too. He waits for Lily to stop. But Lily does not stop. She swings faster and faster. She is having too much fun.\\n\"Can I swing too, Lily?\" Ben asks. Lily does not hear him. She is too busy swinging. Ben feels sad. He walks away.\\nLily swings so high that she loses her grip. She falls off the swing. She lands on the ground. She hurts her foot. She cries.\\n\"Ow, ow, ow!\" she says. She looks for Ben. She wants him to help her. But Ben is not there. He is gone.\\nLily feels sorry. She wishes she had shared the swing with Ben. She wishes he was there to hug her. She limps to the tree. She sees something hanging from a branch. It is Ben\\'s hat. He left it for her.\\nLily smiles. She thinks Ben is nice. She puts on his hat. She hopes he will come back. She wants to say sorry. She wants to be friends again.', 'instruction': {'prompt:': 'Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would understand. The story should use the verb \"hang\", the noun \"foot\" and the adjective \"cute\". The story has the following features: the story should contain at least one dialogue. Remember to only use simple words!\\n\\nPossible story:', 'words': ['hang', 'foot', 'cute'], 'features': ['Dialogue']}, 'summary': 'Lily and Ben play in the park and Lily gets too caught up in swinging, causing Ben to leave. Lily falls off the swing and hurts herself, but Ben leaves his hat for her as a kind gesture.', 'source': 'GPT-4'}\n"
     ]
    }
   ],
   "source": [
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vocab(vocab_size):\n",
    "    \"\"\"\n",
    "    Trains a custom sentencepiece tokenizer on the TinyStories dataset.\n",
    "    The custom tokenizer files will be saved in DATA_CACHE_DIR/tok{N} directories,\n",
    "    where N is the vocab size. This is also where the pretok .bin files will go.\n",
    "    \"\"\"\n",
    "    # 断言词汇表大小必须为正数\n",
    "    assert vocab_size > 0, \"Vocab size must be positive\"\n",
    "\n",
    "    # 设置sentencepiece输出文件的前缀路径\n",
    "    prefix = os.path.join(DATA_CACHE_DIR, f\"tok{vocab_size}\")\n",
    "\n",
    "    # 设置用于词汇表训练的数据分片数量，数量较少以提高效率\n",
    "    num_shards = 10\n",
    "\n",
    "    # 1) 导出一大块文本作为单个文本文件tiny.txt\n",
    "    tiny_file = os.path.join(DATA_CACHE_DIR, \"tiny.txt\")\n",
    "    data_dir = os.path.join(DATA_CACHE_DIR, \"TinyStories_all_data\")\n",
    "    shard_filenames = sorted(glob.glob(os.path.join(data_dir, \"*.json\")))\n",
    "\n",
    "    print(f\"Writing temporary file {tiny_file} with {num_shards} shards...\")\n",
    "    # 打开一个输出文件tiny.txt以写入模式\n",
    "    with open(tiny_file, \"w\", encoding=\"utf-8\") as of:\n",
    "        # 遍历前num_shards个数据分片\n",
    "        for shard in tqdm(shard_filenames[:num_shards]):\n",
    "            with open(shard, \"r\") as f:\n",
    "                data = json.load(f)  # 读取JSON文件内容\n",
    "            # 从每个数据分片中提取故事文本\n",
    "            for example in data:\n",
    "                text = example[\"story\"]\n",
    "                text = text.strip()\n",
    "                of.write(text + \"\\n\")  # 写入每个故事到tiny.txt\n",
    "    print(f\"Size is: {os.path.getsize(tiny_file) / 1024 / 1024:.2f} MB\")  # 打印文件大小\n",
    "\n",
    "    # 2) 使用sentencepiece模型训练分词器\n",
    "    print(\"Will now train the vocab...\")\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=tiny_file,            # 输入文本文件\n",
    "        model_prefix=prefix,        # 模型输出文件的前缀\n",
    "        model_type=\"bpe\",           # 使用BPE（字节对编码）模型\n",
    "        vocab_size=vocab_size,      # 设置词汇表大小\n",
    "        self_test_sample_size=0,    # 自测试样本大小，设置为0表示不使用\n",
    "        input_format=\"text\",        # 输入格式为纯文本\n",
    "        character_coverage=1.0,     # 字符覆盖率为1.0，表示全部字符都覆盖\n",
    "        num_threads=os.cpu_count(), # 使用的线程数为CPU的核心数\n",
    "        split_digits=True,          # 拆分数字\n",
    "        allow_whitespace_only_pieces=True, # 允许只有空格的分片\n",
    "        byte_fallback=True,         # 启用字节回退\n",
    "        unk_surface=r\" \\342\\201\\207 \",  # 未知字符的表示方式\n",
    "        normalization_rule_name=\"identity\" # 使用identity正则化规则\n",
    "    )\n",
    "\n",
    "    # 3) 可选的清理操作，询问用户是否删除临时文件\n",
    "    dec = input(f\"Delete the temporary file {tiny_file}? [y/N] \")\n",
    "    if dec.lower() == \"y\":\n",
    "        os.remove(tiny_file)  # 删除临时文件\n",
    "        print(f\"Deleted {tiny_file}\")\n",
    "\n",
    "    # 打印训练完成的信息\n",
    "    print(f\"Trained tokenizer is in {prefix}.model\")\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing temporary file data/tiny.txt with 10 shards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:36<00:00,  3.65s/it]\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data/tiny.txt\n",
      "  input_format: text\n",
      "  model_prefix: data/tok2048\n",
      "  model_type: BPE\n",
      "  vocab_size: 2048\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 1\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 1\n",
      "  required_chars: \n",
      "  byte_fallback: 1\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  \\342\\201\\207 \n",
      "  enable_differential_privacy"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size is: 739.57 MB\n",
      "Will now train the vocab...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: identity\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: data/tiny.txt\n",
      "trainer_interface.cc(147) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(147) LOG(INFO) Loaded 2000000 lines\n",
      "trainer_interface.cc(147) LOG(INFO) Loaded 3000000 lines\n",
      "trainer_interface.cc(124) LOG(WARNING) Too many sentences are loaded! (3992613), which may slow down training.\n",
      "trainer_interface.cc(126) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(129) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 3992613 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x00>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x01>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x02>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x03>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x04>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x05>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x06>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x07>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x08>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x09>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x10>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x11>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x12>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x13>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x14>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x15>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x16>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x17>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x18>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x19>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x20>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x21>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x22>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x23>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x24>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x25>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x26>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x27>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x28>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x29>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x30>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x31>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x32>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x33>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x34>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x35>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x36>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x37>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x38>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x39>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x40>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x41>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x42>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x43>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x44>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x45>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x46>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x47>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x48>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x49>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x50>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x51>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x52>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x53>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x54>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x55>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x56>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x57>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x58>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x59>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x60>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x61>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x62>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x63>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x64>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x65>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x66>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x67>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x68>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x69>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x70>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x71>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x72>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x73>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x74>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x75>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x76>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x77>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x78>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x79>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x80>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x81>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x82>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x83>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x84>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x85>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x86>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x87>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x88>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x89>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x90>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x91>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x92>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x93>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x94>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x95>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x96>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x97>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x98>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x99>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xED>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFF>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=774735836\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 100% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=102\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 3991250 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 3991250\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 136972\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22423839 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4706490 size=20 all=2116 active=1630 piece=▁l\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2945795 size=40 all=3048 active=2562 piece=▁g\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1779759 size=60 all=4079 active=3593 piece=▁u\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1476715 size=80 all=4706 active=4220 piece=▁She\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1190845 size=100 all=5252 active=4766 piece=▁she\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1168318 min_freq=33402\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=971109 size=120 all=5722 active=1458 piece=▁time\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=809985 size=140 all=6173 active=1909 piece=▁but\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=682045 size=160 all=6823 active=2559 piece=ide\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=574609 size=180 all=7275 active=3011 piece=ird\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=493249 size=200 all=7855 active=3591 piece=▁Tom\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=490644 min_freq=34481\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=419569 size=220 all=8288 active=1424 piece=ul\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=368603 size=240 all=8948 active=2084 piece=elt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=339649 size=260 all=9375 active=2511 piece=▁man\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=297472 size=280 all=9718 active=2854 piece=▁like\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=275679 size=300 all=10127 active=3263 piece=ny\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=275511 min_freq=31524\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=246690 size=320 all=10565 active=1409 piece=▁wal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=228005 size=340 all=10858 active=1702 piece=ook\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=216450 size=360 all=11223 active=2067 piece=▁scared\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=199180 size=380 all=11703 active=2547 piece=▁about\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=184233 size=400 all=12017 active=2861 piece=pped\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=184114 min_freq=27795\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=168720 size=420 all=12416 active=1385 piece=▁pret\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=157236 size=440 all=12826 active=1795 piece=▁box\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=148179 size=460 all=13297 active=2266 piece=▁need\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=138693 size=480 all=13718 active=2687 piece=▁pe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=129029 size=500 all=13978 active=2947 piece=▁surpr\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=128740 min_freq=24345\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=121975 size=520 all=14290 active=1311 piece=ink\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=114396 size=540 all=14561 active=1582 piece=▁both\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=109149 size=560 all=14767 active=1788 piece=▁says\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=102783 size=580 all=15081 active=2102 piece=ied\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=96992 size=600 all=15312 active=2333 piece=▁fo\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=96924 min_freq=21451\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=91921 size=620 all=15493 active=1167 piece=▁its\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89203 size=640 all=15844 active=1518 piece=▁Jack\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85496 size=660 all=16031 active=1705 piece=▁wind\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=82699 size=680 all=16259 active=1933 piece=▁garden\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79356 size=700 all=16518 active=2192 piece=▁keep\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=79223 min_freq=19082\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75694 size=720 all=16642 active=1121 piece=▁N\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73150 size=740 all=16911 active=1390 piece=▁cake\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70220 size=760 all=17255 active=1734 piece=▁fr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66473 size=780 all=17421 active=1900 piece=It\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64100 size=800 all=17647 active=2126 piece=▁story\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=64075 min_freq=17089\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60982 size=820 all=17871 active=1223 piece=▁Jo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58118 size=840 all=18219 active=1571 piece=▁face\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56193 size=860 all=18349 active=1701 piece=▁game\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53437 size=880 all=18525 active=1877 piece=▁feeling\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51305 size=900 all=18695 active=2047 piece=Wow\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51271 min_freq=15065\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49833 size=920 all=18988 active=1293 piece=▁tri\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48549 size=940 all=19280 active=1585 piece=▁first\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47439 size=960 all=19451 active=1756 piece=▁hands\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45293 size=980 all=19629 active=1934 piece=ello\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43911 size=1000 all=19750 active=2055 piece=que\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=43825 min_freq=13644\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42727 size=1020 all=19923 active=1146 piece=▁accident\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41584 size=1040 all=20038 active=1261 piece=▁bag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40071 size=1060 all=20172 active=1395 piece=▁song\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39111 size=1080 all=20258 active=1481 piece=▁curi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37474 size=1100 all=20347 active=1570 piece=▁floor\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=37405 min_freq=12312\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36234 size=1120 all=20507 active=1176 piece=▁accidentally\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35224 size=1140 all=20628 active=1297 piece=Mommy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34289 size=1160 all=20697 active=1366 piece=▁candy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33186 size=1180 all=20808 active=1477 piece=▁through\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32255 size=1200 all=21021 active=1690 piece=▁shout\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=32252 min_freq=11117\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31580 size=1220 all=21226 active=1254 piece=▁ve\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30742 size=1240 all=21386 active=1414 piece=▁goodbye\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29678 size=1260 all=21578 active=1606 piece=▁ste\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28941 size=1280 all=21781 active=1809 piece=thy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28131 size=1300 all=21950 active=1978 piece=▁reach\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28120 min_freq=9452\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27487 size=1320 all=22204 active=1350 piece=▁pro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26755 size=1340 all=22392 active=1538 piece=▁There\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26114 size=1360 all=22491 active=1637 piece=ich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25329 size=1380 all=22668 active=1814 piece=llie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24531 size=1400 all=22887 active=2033 piece=▁gif\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24451 min_freq=8377\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23784 size=1420 all=23062 active=1317 piece=▁rel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22980 size=1440 all=23304 active=1559 piece=▁waved\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22434 size=1460 all=23411 active=1666 piece=cket\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21842 size=1480 all=23540 active=1795 piece=▁key\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21226 size=1500 all=23739 active=1994 piece=oun\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21219 min_freq=7660\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20753 size=1520 all=23838 active=1265 piece=▁gi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20325 size=1540 all=23984 active=1411 piece=ming\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19820 size=1560 all=24244 active=1671 piece=▁wel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19274 size=1580 all=24425 active=1852 piece=▁crab\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18684 size=1600 all=24648 active=2075 piece=▁Gra\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18588 min_freq=6969\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18145 size=1620 all=24783 active=1354 piece=▁patient\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17838 size=1640 all=24864 active=1435 piece=app\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17475 size=1660 all=24969 active=1540 piece=▁bottle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17181 size=1680 all=25129 active=1700 piece=▁Buddy\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: data/tok2048.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: data/tok2048.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained tokenizer is in data/tok2048.model\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_vocab(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_model_path(vocab_size):\n",
    "    \"\"\"\n",
    "    Returns path to the sentencepiece tokenizer model for a given vocab size\n",
    "    vocab_size = 0 designates the default Llama 2 tokenizer, in that case\n",
    "    None is returned.\n",
    "    \"\"\"\n",
    "    if vocab_size == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return os.path.join(DATA_CACHE_DIR, f\"tok{vocab_size}.model\")\n",
    "\n",
    "class Task:\n",
    "\n",
    "    @staticmethod\n",
    "    def iter_batches(batch_size, device, num_workers=0, **dataset_kwargs):\n",
    "        ds = PretokDataset(**dataset_kwargs)\n",
    "        dl = torch.utils.data.DataLoader(\n",
    "            ds, batch_size=batch_size, pin_memory=True, num_workers=num_workers\n",
    "        )\n",
    "        for x, y in dl:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_shard(args, vocab_size):\n",
    "    shard_id, shard = args  # 解包输入参数，shard_id是分片ID，shard是分片文件路径\n",
    "    tokenizer_model = get_tokenizer_model_path(vocab_size)  # 获取分词器模型的路径\n",
    "    enc = Tokenizer(tokenizer_model)  # 初始化分词器对象\n",
    "    with open(shard, \"r\") as f:\n",
    "        data = json.load(f)  # 读取JSON文件内容\n",
    "    \n",
    "    all_tokens = []  # 用于存储所有的分词结果\n",
    "    for example in tqdm(data, position=shard_id):  # 遍历分片中的每个故事\n",
    "        text = example[\"story\"]\n",
    "        text = text.strip()  # 去除前后空格\n",
    "        tokens = enc.encode(text, bos=True, eos=False)  # 对文本进行编码，添加BOS（句子开始）标记\n",
    "        all_tokens.extend(tokens)  # 将编码后的令牌添加到all_tokens列表中\n",
    "    \n",
    "    # 将所有令牌转换为uint16类型的NumPy数组\n",
    "    all_tokens = np.array(all_tokens, dtype=np.uint16)\n",
    "    \n",
    "    # 计算输出文件名\n",
    "    if vocab_size == 0:\n",
    "        # 如果使用的是Llama 2模型，将分词后的文件保存在同一目录\n",
    "        tokenized_filename = shard.replace(\".json\", \".bin\")\n",
    "    else:\n",
    "        # 将二进制文件保存到新的tok{N}目录中\n",
    "        bin_dir = os.path.join(DATA_CACHE_DIR, f\"tok{vocab_size}\")\n",
    "        shard_basename = os.path.basename(shard)\n",
    "        bin_basename = shard_basename.replace(\".json\", \".bin\")\n",
    "        tokenized_filename = os.path.join(bin_dir, bin_basename)\n",
    "    \n",
    "    # 将令牌写入二进制文件\n",
    "    with open(tokenized_filename, \"wb\") as f:\n",
    "        f.write(all_tokens.tobytes())\n",
    "    \n",
    "    # 计算平均序列长度（使用BOS=1分隔序列）\n",
    "    avg_seq_len = all_tokens.size / ((all_tokens == 1).sum())\n",
    "    print(f\"Saved {tokenized_filename}, average seqlen: {avg_seq_len:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
