{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import struct\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArgs:\n",
    "    # default hyperparameters for the Llama 7B model\n",
    "    dim: int = 4096\n",
    "    n_layers: int = 32\n",
    "    n_heads: int = 32\n",
    "    n_kv_heads: Optional[int] = None\n",
    "    vocab_size: int = 32000\n",
    "    hidden_dim: Optional[int] = None\n",
    "    multiple_of: int = 256  # MLP hidden layer size will be multiple of\n",
    "    norm_eps: float = 1e-5\n",
    "    max_seq_len: int = 2048\n",
    "    dropout: float = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ModelArgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama2的RMSNorm层的公式如下：\n",
    "\n",
    "$$\\text{RMSNorm}(x) = \\frac{x}{\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}w_i^2 + \\epsilon}}$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- ( $x$ ) 是层的输入。\n",
    "- ( $w_i$ ) 代表层的权重。\n",
    "- ( $n$ ) 是权重的数量。\n",
    "- ( $\\epsilon$ ) 是一个小常数，用于数值稳定性（以避免除以零的情况）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = RMSNorm(dim=args.dim, eps=args.norm_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0775,  0.5726, -0.6247,  ..., -0.5622, -0.2373,  1.5117],\n",
      "         [-0.8565,  0.0924,  0.6640,  ...,  1.5508, -0.3674, -0.0278],\n",
      "         [-0.0271,  0.6549,  1.0562,  ...,  0.3711,  1.8829,  2.1884],\n",
      "         ...,\n",
      "         [ 0.7752, -1.1106, -0.6566,  ..., -1.0418,  0.2752, -0.6765],\n",
      "         [-0.8082,  1.6563, -0.0736,  ...,  0.9074,  0.7618,  0.5002],\n",
      "         [-0.2666, -1.7303,  2.4673,  ..., -0.3045,  0.8025, -0.6515]]])\n",
      "tensor([[[-1.0494,  0.5577, -0.6083,  ..., -0.5475, -0.2311,  1.4722],\n",
      "         [-0.8461,  0.0913,  0.6559,  ...,  1.5320, -0.3630, -0.0275],\n",
      "         [-0.0266,  0.6421,  1.0355,  ...,  0.3638,  1.8460,  2.1455],\n",
      "         ...,\n",
      "         [ 0.7662, -1.0978, -0.6490,  ..., -1.0298,  0.2721, -0.6687],\n",
      "         [-0.8157,  1.6717, -0.0743,  ...,  0.9158,  0.7688,  0.5048],\n",
      "         [-0.2678, -1.7377,  2.4779,  ..., -0.3058,  0.8060, -0.6543]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 写一个关于norm的测试\n",
    "\n",
    "x = torch.randn(1, 50, 4096) # bs, seq_len, dim\n",
    "print(x)\n",
    "print(norm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设 $\\text{dim}$ 是输入维度，$\\text{end}$ 是序列的长度，$\\theta$ 是比例因子（默认为 10000.0）。\n",
    "\n",
    "1. **频率计算**:\n",
    "   $$\\text{freqs} = \\frac{1}{\\theta^{\\frac{2i}{\\text{dim}}}}$$\n",
    "   其中 $i = 0, 1, 2, ..., \\frac{\\text{dim}}{2} - 1$。\n",
    "\n",
    "2. **时间序列与频率的外积**:\n",
    "   创建一个从 0 到 $\\text{end} - 1$ 的时间序列$t$，并计算 $t$ 和 $\\text{freqs}$ 的外积得到频率矩阵。\n",
    "\n",
    "3. **余弦和正弦值计算**:\n",
    "   - 余弦值：$\\text{freqs\\_cos} = \\cos(\\text{freqs\\_matrix})$\n",
    "   - 正弦值：$\\text{freqs\\_sin} = \\sin(\\text{freqs\\_matrix})$\n",
    "\n",
    "其中，$\\text{freqs\\_matrix}$ 是时间序列 $t$ 和频率$ \\text{freqs}$ 的外积的结果。\n",
    "\n",
    "\n",
    "这个例子首先定义了函数 `precompute_freqs_cis`。然后，它设置了维度 `dim` 为 10，序列长度 `end` 为 5，并保持默认的比例因子$\\theta = 10000.0$。通过调用这个函数并传入这些参数，它计算了序列中每个位置的余弦和正弦值。最后，这个例子打印了这些计算得到的余弦和正弦值矩阵。\n",
    "\n",
    "这种预计算的余弦和正弦值可以用于例如 Transformer 模型中的位置编码，以提供位置信息，帮助模型理解输入数据中元素的顺序关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cos = torch.cos(freqs)  # real part\n",
    "    freqs_sin = torch.sin(freqs)  # imaginary part\n",
    "    return freqs_cos, freqs_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2048]), torch.Size([50]), torch.Size([50, 2048]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta=10000.0\n",
    "dim=4096\n",
    "end=50\n",
    "\n",
    "freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "t = torch.arange(end, device=freqs.device)\n",
    "res = torch.outer(t, freqs).float() \n",
    "freqs.shape, t.shape, res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 2048]), torch.Size([50, 2048]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos, sin = precompute_freqs_cis(4096, 50)\n",
    "cos.shape, sin.shape    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
